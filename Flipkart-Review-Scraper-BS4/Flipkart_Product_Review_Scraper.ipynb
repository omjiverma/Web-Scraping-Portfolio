{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flipkart-Product-Review-Scraper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yOjuGEbTW1kp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify header\n",
        "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
        "# dictionary for storing data\n",
        "reviews ={'Review Title':[],'Review Description':[],'Ratings':[]}"
      ],
      "metadata": {
        "id": "-jpZtLCtW3K1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def review(link):\n",
        "  content_html = requests.get(link,headers=hdr).text\n",
        "  #Convert html page to beautifulsoup object, lxml library to parse html page\n",
        "  soup = BeautifulSoup(content_html,'lxml')\n",
        "  name = (soup.select('._2qfgz2'))[0].getText()\n",
        "  block = soup.select('.K0kLPL')\n",
        "  for b in block:\n",
        "    #Selecting review title, review, review ratings\n",
        "    title = b.select('._2-N8zT')[0].getText()\n",
        "    description = b.select('.t-ZTKy')[0].div.div.getText()\n",
        "    rating = b.select('._3LWZlK ')[0].getText()\n",
        "    #append review to dict\n",
        "    reviews['Review Title'].append(title)\n",
        "    reviews['Review Description'].append(description)\n",
        "    reviews['Ratings'].append(rating)\n",
        "    \n",
        "  #Get next page  \n",
        "  try:\n",
        "    next_page = 'https://www.flipkart.com'+ soup.select('._1LKTO3')[0].attrs['href']\n",
        "    print('.',end=' ')\n",
        "    review(next_page)\n",
        "  except:\n",
        "    print('All Page Scraped')\n",
        "  # Convert dict to pandas data frame and save as a csv file\n",
        "  df = pd.DataFrame.from_dict(reviews)\n",
        "  df.to_csv(f'{name}.csv')"
      ],
      "metadata": {
        "id": "s8Bs8FwpW6sq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = input('Enter all review page url :')\n",
        "review(url)"
      ],
      "metadata": {
        "id": "MRXbPdsQYXuK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}